"""
ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ëª¨ë“ˆ
- user query â†’ embedding vector í˜•íƒœë¡œ ë³€í™˜
"""

from sentence_transformers import SentenceTransformer
from typing import List, Union
import numpy as np

# ì„ë² ë”© ëª¨ë¸ (ì‹±ê¸€í†¤)
_embedding_model = None
EMBEDDING_MODEL_NAME = "jhgan/ko-sroberta-multitask"


def get_embedding_model() -> SentenceTransformer:
    """
    ì„ë² ë”© ëª¨ë¸ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    global _embedding_model
    
    if _embedding_model is None:
        print(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘: {EMBEDDING_MODEL_NAME}")
        _embedding_model = SentenceTransformer(EMBEDDING_MODEL_NAME)
    
    return _embedding_model


def embed_text(text: str) -> np.ndarray:
    """
    ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤.
    
    Args:
        text: ì„ë² ë”©í•  í…ìŠ¤íŠ¸
        
    Returns:
        ì„ë² ë”© ë²¡í„° (numpy array)
    """
    model = get_embedding_model()
    embedding = model.encode(text, convert_to_numpy=True)
    return embedding


def embed_texts(texts: List[str], show_progress: bool = False) -> np.ndarray:
    """
    ì—¬ëŸ¬ í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©í•©ë‹ˆë‹¤.
    
    Args:
        texts: ì„ë² ë”©í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
        show_progress: ì§„í–‰ë¥  í‘œì‹œ ì—¬ë¶€
        
    Returns:
        ì„ë² ë”© ë²¡í„° ë°°ì—´ (N x embedding_dim)
    """
    model = get_embedding_model()
    embeddings = model.encode(
        texts,
        convert_to_numpy=True,
        show_progress_bar=show_progress
    )
    return embeddings


def embed_query(query: str) -> List[float]:
    """
    ì¿¼ë¦¬ë¥¼ ì„ë² ë”©í•˜ê³  ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    (ChromaDB í˜¸í™˜ìš©)
    
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
        
    Returns:
        ì„ë² ë”© ë²¡í„° (list)
    """
    embedding = embed_text(query)
    return embedding.tolist()


def compute_similarity(embedding1: np.ndarray, embedding2: np.ndarray) -> float:
    """
    ë‘ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
    
    Args:
        embedding1: ì²« ë²ˆì§¸ ì„ë² ë”©
        embedding2: ë‘ ë²ˆì§¸ ì„ë² ë”©
        
    Returns:
        ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (0~1)
    """
    dot_product = np.dot(embedding1, embedding2)
    norm1 = np.linalg.norm(embedding1)
    norm2 = np.linalg.norm(embedding2)
    
    if norm1 == 0 or norm2 == 0:
        return 0.0
    
    return dot_product / (norm1 * norm2)


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    print("\n" + "="*60)
    print("ğŸ”¤ ì„ë² ë”© ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    test_texts = [
        "ì‚¬íšŒí™”ëŠ” ê°œì¸ì´ ì‚¬íšŒ êµ¬ì„±ì›ìœ¼ë¡œì„œ í•„ìš”í•œ ê°€ì¹˜ì™€ ê·œë²”ì„ í•™ìŠµí•˜ëŠ” ê³¼ì •ì´ë‹¤.",
        "ë¬¸í™”ëŠ” í•œ ì‚¬íšŒì˜ êµ¬ì„±ì›ë“¤ì´ ê³µìœ í•˜ëŠ” ìƒí™œ ì–‘ì‹ì˜ ì´ì²´ì´ë‹¤."
    ]
    
    for text in test_texts:
        embedding = embed_text(text)
        print(f"\nğŸ“ í…ìŠ¤íŠ¸: {text[:30]}...")
        print(f"   ì„ë² ë”© shape: {embedding.shape}")
        print(f"   ì„ë² ë”© ìƒ˜í”Œ: {embedding[:5]}...")
    
    # ìœ ì‚¬ë„ ê³„ì‚°
    emb1 = embed_text(test_texts[0])
    emb2 = embed_text(test_texts[1])
    similarity = compute_similarity(emb1, emb2)
    print(f"\nğŸ”— ë‘ í…ìŠ¤íŠ¸ ê°„ ìœ ì‚¬ë„: {similarity:.4f}")
    
    print("\nâœ… ì„ë² ë”© ëª¨ë“ˆ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


