"""
ê²€ìƒ‰ ëª¨ë¸ ì´ˆê¸°í™” ëª¨ë“ˆ (STEP 5)
- ChromaDB ë˜ëŠ” FAISSë¥¼ ì‚¬ìš©í•˜ì—¬ ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰
- NumPy í´ë°± ì§€ì›
- ê²€ìƒ‰ ì¸ë±ìŠ¤ ì„¤ì • ë° top-k ê²€ìƒ‰ í•¨ìˆ˜ ì •ì˜
"""

import json
import numpy as np
from pathlib import Path
from typing import List, Dict, Optional, Tuple

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •
PROJECT_ROOT = Path(__file__).parent.parent
DATA_DIR = PROJECT_ROOT / "data"
VECTOR_DB_DIR = DATA_DIR / "vector_db"
CHUNKS_DIR = DATA_DIR / "chunks"


class SearchModel:
    """
    ë²¡í„° ê²€ìƒ‰ ëª¨ë¸ í´ë˜ìŠ¤
    ChromaDB, FAISS, NumPy ì¤‘ ì‚¬ìš© ê°€ëŠ¥í•œ ê²ƒì„ ìë™ ì„ íƒí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, collection_name: str = "social_culture", backend: str = "auto"):
        """
        ê²€ìƒ‰ ëª¨ë¸ì„ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        
        Args:
            collection_name: ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„
            backend: "chroma", "faiss", "numpy", "auto"
        """
        self.collection_name = collection_name
        self.backend = backend
        self.embedding_model = None
        
        # ë°±ì—”ë“œë³„ ë¦¬ì†ŒìŠ¤
        self.chroma_client = None
        self.chroma_collection = None
        self.faiss_index = None
        self.numpy_embeddings = None
        self.chunks = None
        
        self._initialize()
    
    def _initialize(self):
        """
        ê²€ìƒ‰ ë°±ì—”ë“œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
        """
        from sentence_transformers import SentenceTransformer
        
        # ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
        print(f"ğŸ¤– ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘...")
        self.embedding_model = SentenceTransformer("jhgan/ko-sroberta-multitask")
        
        # ì²­í¬ ë°ì´í„° ë¡œë“œ
        self._load_chunks()
        
        # ë°±ì—”ë“œ ì´ˆê¸°í™”
        if self.backend == "auto":
            # ChromaDB ì‹œë„ â†’ FAISS ì‹œë„ â†’ NumPy í´ë°±
            if self._init_chroma():
                self.backend = "chroma"
            elif self._init_faiss():
                self.backend = "faiss"
            else:
                self._init_numpy()
                self.backend = "numpy"
        elif self.backend == "chroma":
            if not self._init_chroma():
                print("âš ï¸ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨, NumPyë¡œ í´ë°±")
                self._init_numpy()
                self.backend = "numpy"
        elif self.backend == "faiss":
            if not self._init_faiss():
                print("âš ï¸ FAISS ì´ˆê¸°í™” ì‹¤íŒ¨, NumPyë¡œ í´ë°±")
                self._init_numpy()
                self.backend = "numpy"
        else:
            self._init_numpy()
            self.backend = "numpy"
        
        print(f"   - ì‚¬ìš© ë°±ì—”ë“œ: {self.backend.upper()}")
        print(f"   - ëª¨ë¸: jhgan/ko-sroberta-multitask")
    
    def _load_chunks(self):
        """ì²­í¬ ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        # combined_all_chunks.json ìš°ì„  ë¡œë“œ
        combined_file = CHUNKS_DIR / "combined_all_chunks.json"
        if combined_file.exists():
            with open(combined_file, 'r', encoding='utf-8') as f:
                chunks_data = json.load(f)
                self.chunks = chunks_data.get('chunks', [])
            print(f"ğŸ“– {len(self.chunks)}ê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ (í†µí•© íŒŒì¼)")
        else:
            chunks_files = list(CHUNKS_DIR.glob("*_chunks.json"))
            if chunks_files:
                with open(chunks_files[0], 'r', encoding='utf-8') as f:
                    chunks_data = json.load(f)
                    self.chunks = chunks_data.get('chunks', [])
                print(f"ğŸ“– {len(self.chunks)}ê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")
    
    def _init_chroma(self) -> bool:
        """ChromaDBë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        try:
            import chromadb
            from chromadb.config import Settings
            
            chroma_path = str(VECTOR_DB_DIR / "chroma_db")
            print(f"ğŸ“¦ ChromaDB ë¡œë“œ ì¤‘: {chroma_path}")
            
            settings = Settings(anonymized_telemetry=False)
            self.chroma_client = chromadb.PersistentClient(path=chroma_path, settings=settings)
            self.chroma_collection = self.chroma_client.get_collection(name=self.collection_name)
            
            print(f"   - ì»¬ë ‰ì…˜: {self.collection_name}")
            print(f"   - ë¬¸ì„œ ìˆ˜: {self.chroma_collection.count()}")
            return True
        except Exception as e:
            print(f"âš ï¸ ChromaDB ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _init_faiss(self) -> bool:
        """FAISS ì¸ë±ìŠ¤ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            import faiss
            
            index_path = str(VECTOR_DB_DIR / "faiss_index.bin")
            print(f"ğŸ“¦ FAISS ë¡œë“œ ì¤‘: {index_path}")
            
            self.faiss_index = faiss.read_index(index_path)
            print(f"   - ë²¡í„° ìˆ˜: {self.faiss_index.ntotal}")
            return True
        except Exception as e:
            print(f"âš ï¸ FAISS ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def _init_numpy(self) -> bool:
        """NumPy ì„ë² ë”©ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        try:
            embeddings_path = VECTOR_DB_DIR / "embeddings.npy"
            print(f"ğŸ“¦ NumPy ì„ë² ë”© ë¡œë“œ ì¤‘: {embeddings_path}")
            
            self.numpy_embeddings = np.load(str(embeddings_path))
            print(f"   - ë²¡í„° ìˆ˜: {len(self.numpy_embeddings)}")
            print(f"   - ì°¨ì›: {self.numpy_embeddings.shape[1]}")
            return True
        except Exception as e:
            print(f"âš ï¸ NumPy ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False
    
    def embed_query(self, query: str) -> np.ndarray:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”© ë²¡í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤."""
        return self.embedding_model.encode(query)
    
    def search(
        self,
        query: str,
        top_k: int = 5,
        include_distances: bool = True
    ) -> List[Dict]:
        """ì¿¼ë¦¬ì™€ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        
        if self.backend == "chroma":
            return self._search_chroma(query, top_k)
        elif self.backend == "faiss":
            return self._search_faiss(query, top_k)
        else:
            return self._search_numpy(query, top_k)
    
    def _search_chroma(self, query: str, top_k: int) -> List[Dict]:
        """ChromaDBë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        query_embedding = self.embed_query(query).tolist()
        
        results = self.chroma_collection.query(
            query_embeddings=[query_embedding],
            n_results=top_k,
            include=["documents", "metadatas", "distances"]
        )
        
        search_results = []
        if results and results['documents']:
            documents = results['documents'][0]
            metadatas = results['metadatas'][0] if results['metadatas'] else [{}] * len(documents)
            distances = results['distances'][0] if results['distances'] else [0] * len(documents)
            ids = results['ids'][0] if results['ids'] else [''] * len(documents)
            
            for i, (doc, meta, dist, doc_id) in enumerate(zip(documents, metadatas, distances, ids)):
                # source_fileì´ metadataì— ì—†ìœ¼ë©´ chunksì—ì„œ ì°¾ê¸°
                if 'source_file' not in meta and self.chunks:
                    try:
                        # global_chunk_id ì‚¬ìš© (metadataì— ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
                        global_chunk_id = meta.get('global_chunk_id')
                        if global_chunk_id is None:
                            # doc_idì—ì„œ ì¸ë±ìŠ¤ ì¶”ì¶œ (ì˜ˆ: "chunk_123" -> 123)
                            if '_' in doc_id:
                                global_chunk_id = int(doc_id.split('_')[-1])
                        
                        if global_chunk_id is not None and global_chunk_id < len(self.chunks):
                            chunk = self.chunks[global_chunk_id]
                            if 'source_file' in chunk:
                                meta['source_file'] = chunk['source_file']
                    except Exception as e:
                        pass
                
                result = {
                    "rank": i + 1,
                    "id": doc_id,
                    "text": doc,
                    "metadata": meta,
                    "distance": dist,
                    "similarity": 1 - dist
                }
                search_results.append(result)
        
        return search_results
    
    def _search_faiss(self, query: str, top_k: int) -> List[Dict]:
        """FAISSë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        query_embedding = self.embed_query(query).reshape(1, -1).astype('float32')
        
        distances, indices = self.faiss_index.search(query_embedding, top_k)
        
        search_results = []
        for rank, (idx, dist) in enumerate(zip(indices[0], distances[0])):
            if idx < 0:
                continue
            
            chunk = self.chunks[idx] if self.chunks and idx < len(self.chunks) else {}
            
            result = {
                "rank": rank + 1,
                "id": f"chunk_{idx}",
                "text": chunk.get('text', ''),
                "metadata": {
                    "page_number": chunk.get('page_number', 0),
                    "chunk_id": chunk.get('chunk_id', idx),
                    "char_count": chunk.get('char_count', 0),
                    "source_file": chunk.get('source_file', '')  # PDF íŒŒì¼ ì´ë¦„ ì¶”ê°€
                },
                "distance": float(dist),
                "similarity": 1 / (1 + float(dist))  # L2 ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜
            }
            search_results.append(result)
        
        return search_results
    
    def _search_numpy(self, query: str, top_k: int) -> List[Dict]:
        """NumPyë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        query_embedding = self.embed_query(query)
        
        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        query_norm = query_embedding / np.linalg.norm(query_embedding)
        embeddings_norm = self.numpy_embeddings / np.linalg.norm(self.numpy_embeddings, axis=1, keepdims=True)
        similarities = np.dot(embeddings_norm, query_norm)
        
        # top-k ì¸ë±ìŠ¤
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        search_results = []
        for rank, idx in enumerate(top_indices):
            chunk = self.chunks[idx] if self.chunks and idx < len(self.chunks) else {}
            
            result = {
                "rank": rank + 1,
                "id": f"chunk_{idx}",
                "text": chunk.get('text', ''),
                "metadata": {
                    "page_number": chunk.get('page_number', 0),
                    "chunk_id": chunk.get('chunk_id', idx),
                    "char_count": chunk.get('char_count', 0),
                    "source_file": chunk.get('source_file', '')  # PDF íŒŒì¼ ì´ë¦„ ì¶”ê°€
                },
                "distance": 1 - similarities[idx],
                "similarity": float(similarities[idx])
            }
            search_results.append(result)
        
        return search_results
    
    def search_with_filter(
        self,
        query: str,
        top_k: int = 5,
        page_filter: Optional[Tuple[int, int]] = None
    ) -> List[Dict]:
        """í•„í„°ë¥¼ ì ìš©í•˜ì—¬ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        all_results = self.search(query, top_k=top_k * 3)
        
        if page_filter:
            start_page, end_page = page_filter
            filtered = [
                r for r in all_results
                if start_page <= r['metadata'].get('page_number', 0) <= end_page
            ]
            for i, r in enumerate(filtered[:top_k]):
                r['rank'] = i + 1
            return filtered[:top_k]
        
        return all_results[:top_k]


def get_search_model(collection_name: str = "social_culture", backend: str = "auto") -> SearchModel:
    """ê²€ìƒ‰ ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    return SearchModel(collection_name=collection_name, backend=backend)


def format_search_results(results: List[Dict], show_text: bool = True) -> str:
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    output = []
    
    for result in results:
        output.append(f"\n[{result['rank']}ìœ„] ìœ ì‚¬ë„: {result['similarity']:.4f}")
        output.append(f"   í˜ì´ì§€: {result['metadata'].get('page_number', 'N/A')}")
        
        if show_text:
            text = result['text']
            if len(text) > 200:
                text = text[:200] + "..."
            output.append(f"   ë‚´ìš©: {text}")
    
    return "\n".join(output)


# í…ŒìŠ¤íŠ¸ ì½”ë“œ
if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ” ê²€ìƒ‰ ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("="*60)
    
    # ê²€ìƒ‰ ëª¨ë¸ ì´ˆê¸°í™” (ìë™ ë°±ì—”ë“œ ì„ íƒ)
    search_model = get_search_model()
    
    # í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬
    test_queries = [
        "ì‚¬íšŒí™”ë€ ë¬´ì—‡ì¸ê°€?",
        "ë¬¸í™”ì˜ íŠ¹ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì¤˜"
    ]
    
    for query in test_queries:
        print(f"\n{'='*60}")
        print(f"ğŸ” ì¿¼ë¦¬: {query}")
        print("="*60)
        
        results = search_model.search(query, top_k=3)
        print(format_search_results(results))
    
    print("\n" + "="*60)
    print("âœ… ê²€ìƒ‰ ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*60 + "\n")
